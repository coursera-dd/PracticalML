<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Daniel Damian" />

<meta name="date" content="2017-06-20" />

<title>Prediction Assignment Project</title>

<script src="project_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="project_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="project_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="project_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="project_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="project_files/navigation-1.1/tabsets.js"></script>
<link href="project_files/highlightjs-1.1/default.css" rel="stylesheet" />
<script src="project_files/highlightjs-1.1/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>



<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Prediction Assignment Project</h1>
<h4 class="author"><em>Daniel Damian</em></h4>
<h4 class="date"><em>20 June 2017</em></h4>

</div>


<p>Let’s start by loading the libraries and the data in. We observe that a number of supposedly numerical fields contain <code>#DIV/0!</code> as a value (someone has been using Excel) and we take care to consider these values as <code>NA</code> (even if possibly these could indicate something different than the non-value).</p>
<pre class="r"><code>library(ggplot2);library(grid);library(gridExtra);library(caret);library(klaR);</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## Loading required package: MASS</code></pre>
<pre class="r"><code>trdata &lt;- read.csv(&quot;Y:\\Learning\\PracticalMachineLearning\\pml-training.csv&quot;,na.strings = c(&#39;NA&#39;, &#39;#DIV/0!&#39;));
tsdata &lt;- read.csv(&quot;Y:\\Learning\\PracticalMachineLearning\\pml-testing.csv&quot;, na.strings = c(&#39;NA&#39;, &#39;#DIV/0!&#39;));</code></pre>
<p>First, for some exploratory analyses, we can try to see some patterns in the data using several plots</p>
<pre class="r"><code>pgeom&lt;-geom_point(alpha=0.3, size=0.3);
p1&lt;-ggplot(trdata, aes(x=roll_arm, y=pitch_arm, col=classe))+pgeom;
p2&lt;-ggplot(trdata, aes(x=accel_dumbbell_x, y=accel_dumbbell_y, col=classe))+pgeom;
p3&lt;-ggplot(trdata, aes(x=accel_belt_x, y=accel_belt_z, col=classe))+pgeom;
p4&lt;-ggplot(trdata, aes(x=roll_forearm, y=pitch_forearm, col=classe))+pgeom;
grid.arrange(p1, p2, p3, p4, ncol=2, nrow=2);</code></pre>
<p><img src="project_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>We see that there are complex patterns at play, some that suggest that linear models may not be very useful. Also it’s worth observing that measurements are taken in sequence, and it is the sequence of measurements that defines a pattern of correct or wrong movement (class).</p>
<p>The task is however to provide instant input, therefore predict the class based on a single time point irrespective of the time window.</p>
<p>To make analysis easier, we remove some variables that may introduce a skew. For instance, we notice that the rows are sorted in order of class, so in order to avoid a fake linearity being introduced by the row number we remove it. We also remove fields that have to do with the user, timestamp and time window.</p>
<p>We calculate a list of fields that we will remove from both data frames. This will include aggregated calculations that are available for time window rows only.</p>
<pre class="r"><code>trnames &lt;- names(trdata);
rtrNames &lt;-c(&#39;X&#39;,&#39;user_name&#39;,&#39;raw_timestamp_part_1&#39;,&#39;raw_timestamp_part_2&#39;,&#39;cvtd_timestamp&#39;,&#39;new_window&#39;,&#39;num_window&#39;,trnames[grepl(&#39;kurtosis|skewness|max_|min_|amplitude_|var_|avg_|stddev_&#39;, trnames)])
tsnames &lt;- names(tsdata);
rtsNames &lt;-c(&#39;X&#39;,&#39;user_name&#39;,&#39;raw_timestamp_part_1&#39;,&#39;raw_timestamp_part_2&#39;,&#39;cvtd_timestamp&#39;,&#39;new_window&#39;,&#39;num_window&#39;,tsnames[grepl(&#39;kurtosis|skewness|max_|min_|amplitude_|var_|avg_|stddev_&#39;, tsnames)])</code></pre>
<p>We recreate the training and test data removing the non-important names and we check that we don’t have <code>NA</code> values.</p>
<pre class="r"><code>strdata &lt;- trdata[, trnames[!(trnames %in% rtrNames)]];
stsdata &lt;- tsdata[, tsnames[!(tsnames %in% rtsNames)]];
all(colSums(is.na(strdata))==0);</code></pre>
<pre><code>## [1] TRUE</code></pre>
<pre class="r"><code>all(colSums(is.na(stsdata))==0);</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>The <code>classe</code> variable is the prediction variable, we split the data into a training and a test</p>
<pre class="r"><code>set.seed(54321)
inTrain &lt;- createDataPartition(strdata$classe, p=0.7, list=FALSE);
training &lt;- strdata[inTrain, ];
testing &lt;- strdata[-inTrain, ];</code></pre>
<div id="testing-some-simple-models" class="section level2">
<h2>Testing some simple models</h2>
<p>We try first a few simple models - a Linear Discriminant Analysis after a PCA transformation, a Naive Bayes on a PCA transformation with 10 components and a naive Bayes on the original data set.</p>
<pre class="r"><code>preproc &lt;- preProcess(training[,-53], method=&quot;pca&quot;, pcaComp=10)
trainingPC&lt;-predict(preproc, training[,-53]);
testingPC&lt;-predict(preproc, testing[,-53]);
ctrl &lt;- trainControl(preProcOptions = list(thresh = 0.90));
modlda    &lt;- train(classe ~ ., method=&quot;lda&quot;, preProcess=&quot;pca&quot;, data=training, trControl = ctrl);
modnbpca  &lt;- NaiveBayes(training$classe ~ ., data=trainingPC);
modnb     &lt;- NaiveBayes(classe ~ ., data=training)</code></pre>
<p>Let’s check the obtained accuracy</p>
<pre class="r"><code>print(confusionMatrix(testing$classe, predict(modlda,   testing))$overall[&#39;Accuracy&#39;]);</code></pre>
<pre><code>##  Accuracy 
## 0.4968564</code></pre>
<pre class="r"><code>print(confusionMatrix(testing$classe, predict(modnbpca, testingPC)$class)$overall[&#39;Accuracy&#39;]);</code></pre>
<pre><code>##  Accuracy 
## 0.4487681</code></pre>
<pre class="r"><code>print(confusionMatrix(testing$classe, predict(modnb,    testing)$class)$overall[&#39;Accuracy&#39;]);</code></pre>
<pre><code>##  Accuracy 
## 0.4776551</code></pre>
<p>Not that great - actually worse than by chance. These models are of not much use.</p>
</div>
<div id="better-models---random-forests-with-cross-validation" class="section level2">
<h2>Better models - random forests with cross-validation</h2>
<p>We need to take another approach - we try random forests</p>
<pre class="r"><code>control &lt;- trainControl(method=&quot;cv&quot;, number=10, repeats=3)
modrf &lt;- train(classe ~ ., data=training, method=&quot;rf&quot;, ntree=100, trControl=control);
cm &lt;- confusionMatrix(testing$classe, predict(modrf,  testing));
print(cm);</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1671    3    0    0    0
##          B    8 1128    3    0    0
##          C    0    5 1017    3    1
##          D    0    0    6  958    0
##          E    0    0    2    2 1078
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9944          
##                  95% CI : (0.9921, 0.9961)
##     No Information Rate : 0.2853          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9929          
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9952   0.9930   0.9893   0.9948   0.9991
## Specificity            0.9993   0.9977   0.9981   0.9988   0.9992
## Pos Pred Value         0.9982   0.9903   0.9912   0.9938   0.9963
## Neg Pred Value         0.9981   0.9983   0.9977   0.9990   0.9998
## Prevalence             0.2853   0.1930   0.1747   0.1636   0.1833
## Detection Rate         0.2839   0.1917   0.1728   0.1628   0.1832
## Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
## Balanced Accuracy      0.9973   0.9953   0.9937   0.9968   0.9991</code></pre>
<p>This looks a lot better - in fact this is as good as it gets. We did build the model with cross-validation to avoid over-fitting to the selected training set, and we repeated a few times. In fact, we tried several parameters for tree size and number of cross-validations, and results are fairly similar. Random Forests appear to be inherently suitable for this problem.</p>
<p>The out-of-sample error is</p>
<pre class="r"><code>as.numeric(1-cm$overall[&#39;Accuracy&#39;]);</code></pre>
<pre><code>## [1] 0.005607477</code></pre>
</div>
<div id="predictions" class="section level2">
<h2>Predictions</h2>
<p>Finally we can print out the predictions</p>
<pre class="r"><code>predict(modrf,  stsdata);</code></pre>
<pre><code>##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E</code></pre>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
